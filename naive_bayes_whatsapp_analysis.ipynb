{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes: Whatsapp message classification\n",
    "\n",
    "Using Whatsapp conversation history, we aim at predicting which user has submitted a given message. For it, we will use Bayes theorem under some coarse assumptions. From Bayes theorem, we can write the conditional probability of a message having been sent by a given member of a group as:\n",
    "\n",
    "$$ p(\\text{user} | \\text{message} ) = \\frac{ p(\\text{message} | \\text{user} ) \\cdot p(\\text{user})}{p(\\text{message})} $$\n",
    "\n",
    "First, in contrast to the typical examples of sick vs. healthy, here there is no counterpart to $message$. In other words $p(\\text{message}) = 1$, such that the denominator is constant. The term $p(\\text{user})$ indicates the probability of a randomly selected message to be of the given user. Thus, this is simply given by:\n",
    "\n",
    "$$ p( \\text{user} ) = \\frac{ \\text{\\# messages by user}}{\\text{\\# total messages}} $$\n",
    "\n",
    "Our next goal is to calculate the conditional probability $p(\\text{message} | \\text{user} )$. We can do a coarse assumption an say that the probability of a given message is given by the probabilty of every word, where every word in independent of any previous words. Under this independence framwework: \n",
    "\n",
    "$$ p(\\text{message} | \\text{user} ) =  \\prod_{i=1}^N p( \\text{word}_i | \\text{user}) $$\n",
    "\n",
    "where $N$ is the length of the message. The chances of finding a word for a given user is:\n",
    "\n",
    "$$ p(\\text{word}_i | \\text{user} ) =  \\frac{\\text{\\# occurencies word}_i}{\\text{\\# words by user}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations(path_file):\n",
    "    \"\"\"\n",
    "        Loads the conversation and parses the text for easy manipulation\n",
    "\n",
    "        Parameters:\n",
    "            - path_file (string): Path to the conversation file\n",
    "        \n",
    "        Returns:\n",
    "           - messages :\n",
    "           - members_msg\n",
    "           - members\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    members_msg = []\n",
    "\n",
    "    members = []\n",
    "    members_count = 0\n",
    "\n",
    "    def is_date(date_str):\n",
    "        data = date_str.split(\"/\") # Separator character for the date\n",
    "        if len(data) == 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # TODO: Update\n",
    "    def remove_punctuation(input_string):\n",
    "        # Make a translation table that maps all punctuation characters to None\n",
    "        translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "        # Apply the translation table to the input string\n",
    "        result = input_string.translate(translator)\n",
    "\n",
    "        return result\n",
    "\n",
    "    with open(path_file) as fp:\n",
    "       \n",
    "        for cnt, line in enumerate(fp):\n",
    "            \n",
    "            str_line = ''.join(line)\n",
    "            str_line = str_line.lower()\n",
    "            str_word_list = str_line.split()\n",
    "        \n",
    "            if str_word_list: # Check that it doesnt correspond to an empty message\n",
    "                if is_date(str_word_list[0]) == 1:\n",
    "                    \n",
    "                    # If the line is a citation skip the analyis\n",
    "                    if (str_word_list[0])[0] == \"[\":\n",
    "                        continue\n",
    "\n",
    "                    messages.append(str_word_list[4:])\n",
    "\n",
    "                    tmp_member = str_word_list[3][:-1]  # The -1 is to remove : from the user\n",
    "                    members_msg.append(tmp_member)\n",
    "\n",
    "                    if tmp_member not in members:\n",
    "                        members.append(tmp_member)\n",
    "                        members_count += 1\n",
    "\n",
    "    return messages, members_msg, members\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(messages, members_msg, members):\n",
    "    \"\"\"\n",
    "        Creates a dictionary for every word in the text.\n",
    "        The dictinary is composed of a dictinary of dictionaries containign the\n",
    "        word and the number of times each user has employed the word. \n",
    "        For instance,\n",
    "        \n",
    "        word_dict = {\n",
    "                        'hello': {\n",
    "                            'alice': 1,\n",
    "                            'bob': 5,\n",
    "                            'charlie': 3\n",
    "                    }\n",
    "\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Creates an empty dictionary\n",
    "    word_dict = {}\n",
    "\n",
    "    for idm, message in enumerate(messages):\n",
    "        mmbr = members_msg[idm]\n",
    "        for word in message:\n",
    "            \n",
    "            # Add word if not in the dictionary\n",
    "            if word not in word_dict.keys():\n",
    "                word_dict[word] = {m: 1 for m in members}\n",
    "\n",
    "            word_dict[word][mmbr] += 1\n",
    "\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, fraction):\n",
    "    \"\"\"\n",
    "        Splits the data in training and cross-validations sets\n",
    "        Parameters:\n",
    "            - X (string arrays) : Messages, composed of array of strings\n",
    "            - Y (array of string) : Classes for each user\n",
    "            - fraction (float) : Proportion of the data to be uset for training\n",
    "        \n",
    "        Returns:\n",
    "           - X_train :\n",
    "           - X_xval : \n",
    "           - Y_train :\n",
    "           - Y_xval :               \n",
    "    \"\"\"     \n",
    "\n",
    "    n_messages = len(X)\n",
    "    num_ones = int(np.round(n_messages*fraction))\n",
    "    \n",
    "    ids = np.int32(np.random.choice(n_messages, num_ones, replace=False))\n",
    "\n",
    "    ids_bool_train = np.zeros(n_messages, dtype=bool)\n",
    "    ids_bool_xval =  np.zeros(n_messages, dtype=bool)\n",
    "    ids_bool_train[ids] = True\n",
    "    ids_bool_xval[~ids_bool_train] = True\n",
    "    \n",
    "    # We do it in that way (instead of X[ids]) because of having an array of strings X[messsage][words], \n",
    "    # which does not allow for the indicated approach \n",
    "    X_train = [X[i] for i in ids]\n",
    "    X_xval = [X[i] for i in  range(0,n_messages) if ids_bool_xval[i]==True]\n",
    "   \n",
    "    Y_train = [Y[i] for i in ids]\n",
    "    Y_xval = [Y[i] for i in  range(0,n_messages) if ids_bool_xval[i]==True]\n",
    "    \n",
    "\n",
    "    return X_train, X_xval, Y_train, Y_xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def messages_by_member(members_msg, member):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return sum(np.array(members_msg)==member)\n",
    "\n",
    "\n",
    "def prob_message_by_members(messages, members_msg, members):\n",
    "    \"\"\"\n",
    "\n",
    "        Creates dictionaries with the number of messages for each of the membeers and their probability\n",
    "\n",
    "    \"\"\"\n",
    "    n_messages = len(messages)\n",
    "    num_messages_members = {member: messages_by_member(members_msg, member) for member in members}\n",
    "    prob_message_members =  {member: messages_by_member(members_msg, member)/n_messages for member in members}\n",
    "    return num_messages_members, prob_message_members\n",
    "\n",
    "\n",
    "def prob_message_given_member(message, member, word_dictionary, num_messages_by_member):\n",
    "\n",
    "    p = 1\n",
    "    for word in message:\n",
    "\n",
    "        if word in word_dictionary.keys(): \n",
    "            p *= word_dictionary[word][member]/num_messages_by_member\n",
    "    return p \n",
    "\n",
    "\n",
    "def naive_bayes_whatsapp_messages(message, members, num_messages_members, prob_message_members, word_dictionary):    \n",
    "    \"\"\"\n",
    "        Naive Bayes classifier for spam detection.\n",
    "\n",
    "        This function calculates the probability of an email being spam (1) or ham (0)\n",
    "        based on the Naive Bayes algorithm. It uses the conditional probabilities of the\n",
    "        treated_email given spam and ham, as well as the prior probabilities of spam and ham\n",
    "        classes. The final decision is made by comparing the calculated probabilities.\n",
    "\n",
    "        Parameters:\n",
    "        - treated_email (list): A preprocessed representation of the input email.\n",
    "        - word_frequency (dict): The dictionary containing the words frequency.\n",
    "        - class_frequency (dict): The dictionary containing the class frequency.\n",
    "        - return_likelihood (bool): If true, it returns the likelihood of both spam and ham.\n",
    "\n",
    "        Returns:\n",
    "        If return_likelihood = False:\n",
    "            - int: 1 if the email is classified as spam, 0 if classified as ham.\n",
    "        If return_likelihood = True:\n",
    "            - tuple: A tuple with the format (spam_likelihood, ham_likelihood)\n",
    " \n",
    "    p_message = np.array(prob_message_given_member(message, member, word_dictionary, num_message_by_member) for member in members)\n",
    "    p_message_given_member = np.array(prob_message_given_member for())\n",
    "    \"\"\"\n",
    "\n",
    "    p_message = {}\n",
    "    message_words = message.split()\n",
    "    for member in members:\n",
    "        p_message_given_member = prob_message_given_member(message_words, member, word_dictionary, num_messages_members[member])\n",
    "        p_member = prob_message_members[member]\n",
    "        print(p_member)\n",
    "        p_message[member] =  p_message_given_member/p_member\n",
    "\n",
    "    return p_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load conversation\n",
    "messages, members_msg, members = load_conversations('./chat_trials.txt') \n",
    "\n",
    "# Split the data in training and cross-validation sets\n",
    "messages_train, messages_xval, members_msg_train, members_msg_xval  = split_data(messages, members_msg, 0.8)\n",
    "\n",
    "# Make dictionary\n",
    "word_dict_train = make_dictionary(messages_train, members_msg_train, members)\n",
    "\n",
    "# Determine probabilities per user\n",
    "num_messages_members, prob_message_members = prob_message_by_members(messages_train, members_msg_train, members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.1\n",
      "0.2\n",
      "0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gonzalo': 2.5, 'clp': 10.0, 'peter': 5.0, 'javier': 3.3333333333333335}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test a sentence\n",
    "naive_bayes_whatsapp_messages(\"Me conformo\", members, num_messages_members, prob_message_members, word_dict_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the performance of the method, we iterate over all messages in the cross validation set.\n",
    "# We should create a 2D array reppresenting the probability of returning a user given that the user was X\n",
    "# Ideally, it should be very high in the diagonal an null or very small in the non-diagonal terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
